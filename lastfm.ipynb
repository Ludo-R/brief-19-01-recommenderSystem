{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "integrated-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "capital-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    totalUsers  totalPlays     avgPlays\n",
      "name                                                   \n",
      "Britney Spears             522     2393140  4584.559387\n",
      "Depeche Mode               282     1301308  4614.567376\n",
      "Lady Gaga                  611     1291387  2113.563011\n",
      "Christina Aguilera         407     1058405  2600.503686\n",
      "Paramore                   399      963449  2414.659148\n",
      "...                        ...         ...          ...\n",
      "Morris                       1           1     1.000000\n",
      "Eddie Kendricks              1           1     1.000000\n",
      "Excess Pressure              1           1     1.000000\n",
      "My Mine                      1           1     1.000000\n",
      "A.M. Architect               1           1     1.000000\n",
      "\n",
      "[17632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plays = pd.read_csv('data/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('data/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "political-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Merge into ap matrix\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\") \\\n",
    "    .sort_values(['playCount'], ascending=False)\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity\n",
    "density = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(\"density: %.2f\" % density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "sensitive-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "\n",
    "# Build a sparse matrix\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "casual-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions, random_state=42)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "tight-platinum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fb8b370abb0>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp', random_state=42)\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "civic-hollow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.38, test 0.13.\n",
      "AUC: train 0.96, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "professional-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Depeche Mode' 'Madonna' 'New Order' ... 'Anata' 'Wayne Marshall'\n",
      " 'Tokyo Gakuso']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "visible-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fb8a48550d0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LightFM(learning_rate=0.08, loss='warp', random_state=42)\n",
    "model2.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-andrew",
   "metadata": {},
   "source": [
    "#### Try some parametter and get a board with better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "compact-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "trp = precision_at_k(model, train, k=10).mean()\n",
    "tep = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "tra = auc_score(model, train).mean()\n",
    "tea = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "dico = {'Loss':'Warp', 'K':10, 'Learning_rate':0.08, 'Train Precision':trp, 'Test Precision':tep, 'Train Auc':tra,'Test Auc':tea}\n",
    "\n",
    "tab = pd.DataFrame(dico.items(), columns=['Parameter', 'Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "coordinated-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Loss</td>\n",
       "      <td>Warp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning_rate</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train Precision</td>\n",
       "      <td>0.377754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test Precision</td>\n",
       "      <td>0.131981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Train Auc</td>\n",
       "      <td>0.964242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test Auc</td>\n",
       "      <td>0.856067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Parameter    Values\n",
       "0             Loss      Warp\n",
       "1                K        10\n",
       "2    Learning_rate      0.08\n",
       "3  Train Precision  0.377754\n",
       "4   Test Precision  0.131981\n",
       "5        Train Auc  0.964242\n",
       "6         Test Auc  0.856067"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "republican-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def scoring():\n",
    "    \n",
    "#    learning_rate = [0.05, 0.08, 0.10]\n",
    "#    losslist = ['logistic', 'bpr', 'warp', 'warp-kos']\n",
    "#    klist = [5, 7, 10]\n",
    "    learning_rate = [0.05, 0.08, 0.10]\n",
    "    losslist = ['bpr', 'warp', 'logistic', 'warp-kos']\n",
    "    klist = [5, 7, 9, 11, 13]\n",
    "    results = []\n",
    "    \n",
    "    for x in learning_rate:\n",
    "        for y in losslist:\n",
    "            for z in klist:\n",
    "            \n",
    "                model = LightFM(learning_rate=x, loss = y)\n",
    "                t1 = time.process_time()\n",
    "                model.fit(train, epochs=10, num_threads=2)\n",
    "                t2 = time.process_time()\n",
    "                t = t2 - t1\n",
    "                trainPrecision = precision_at_k(model, train, k=z).mean()\n",
    "                testPrecision = precision_at_k(model, test, k=z, train_interactions=train).mean()\n",
    "\n",
    "                trainAUC = auc_score(model, train).mean()\n",
    "                testAUC = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "                dicttemp = {}\n",
    "                dicttemp = {'Time:':t, 'K':z, 'Name':y, 'Learning Rate':x, 'Train Precision':trainPrecision, 'Train AUC':trainAUC, 'Test Precision':testPrecision, \"Train AUC\":trainAUC, \"Test AUC\":testAUC}\n",
    "\n",
    "                results.append(dicttemp)\n",
    "            \n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "failing-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user):\n",
    "    scores = model.predict(user, np.arange(n_items))\n",
    "    top_items = artist_names[np.argsort(-scores)]\n",
    "    reco = pd.DataFrame(top_items[:10], columns=['Recommandations'])\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "returning-guitar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommandations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autechre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim Hecker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solar Fields</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bong-Ra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoMeansNo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Red House Painters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Danny Norbury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Recommandations\n",
       "0            Autechre\n",
       "1                Bola\n",
       "2          Tim Hecker\n",
       "3        Solar Fields\n",
       "4              Madlib\n",
       "5             Bong-Ra\n",
       "6           NoMeansNo\n",
       "7                  Ef\n",
       "8  Red House Painters\n",
       "9       Danny Norbury"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "verbal-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get_ground_truth qui renvoie les artistes ecoutés par un utilisateur par ordre décroissant du playCountScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
